{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN(Recurrent Neural Network : 순환신경망)\n",
    "# 상태가 고정된 데이터 (이미지같은)를 처리하는 타 신경망보다\n",
    "# 자연어 혹은 음성처리같은 순서가 있는 데이터를 처리하는데 강점을 가진 신경망이다.\n",
    "# 이번 코드는 MNIST를 RNN 방식으로 학습하고 예측하는 모델을 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 28*28의 이미지에 위에서 아래 순서대로 28픽셀 한줄씩을 내려가면서 데이터를 입력받도록 한다.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_leaning_rate = 0.001\n",
    "hp_total_epoch = 30\n",
    "hp_batch_size = 128\n",
    "\n",
    "hp_n_input = 28\n",
    "hp_n_step = 28\n",
    "hp_n_hidden = 128\n",
    "hp_n_class = 10\n",
    "\n",
    "# 플레이스 홀더의 정의.\n",
    "# 여기서의 입력값 X에서 hp_n_step 이란 차원을 하나 더 추가하였다.\n",
    "# RNN은 순서가 있는 데이터를 다루기 때문에 한번에 입력 받을 개수와 \n",
    "# 총 몇단계로 이루어진 데이터를 받을지를 설정해야 한다.\n",
    "# 이때문에 가로 픽셀수를 hp_n_input으로, 세로 픽셀수를 단계수인 hp_n_step으로 설정하였다.\n",
    "X = tf.placeholder(tf.float32, [None, hp_n_step, hp_n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, hp_n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([hp_n_hidden, hp_n_class]))\n",
    "b = tf.Variable(tf.random_normal([hp_n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose:0\", shape=(?, 28, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# hp_n_hidden (은닉층 수)의 출력값을 갖는 RNN 셀을 생성한다.\n",
    "# 텐서플로우에서는 RNN 셀을 아래와 같이 쉽게 생성할 수 있다.\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(hp_n_hidden)\n",
    "\n",
    "# 셀 생성 함수는 여러 종류가 있는데 \n",
    "# 위의 BasicRNNCell뿐만 아니라 BasicLSTMCell, GRUCell 등의 다양한 방식이 존재한다.\n",
    "\n",
    "# 다음으로는 dynsmic_rnn 함수를 이용하여 RNN 신경망을 만든다.\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "# 위와 같이 RNN셀과 입력값, 입력값의 자료형만 넣어주면 간단하게 신경망을 만들수 있다.\n",
    "# (원래대로 코드를 저수준으로 구현해야 한다면 상당히 복잡하다.)\n",
    "\n",
    "# states = tf.zeros(hp_batch_size)\n",
    "# for i in range(hp_n_step)\n",
    "#     outputs, states = cell(X[[:, i]], states)\n",
    "# 위 코드와 같이 한단계 학습하고 상태를 저장한 후, 그 상태를 다음 단계의 입력 상태로 해서 다시 학습한다.\n",
    "# 이렇게 주어진 단계를 반폭하여 상태를 전파해가면서 출력값을 만드는 구조이다.\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose_1:0\", shape=(28, ?, 128), dtype=float32)\n",
      "Tensor(\"strided_slice:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 이제는 RNN에서 나온 출력 값을 가지고 최종 출력을 만들 차례다.\n",
    "# 결과값은 One-hot 인코딩 형태이므로 손실 함수로 tf.nn.softmax_cross_entropy_with_logits를 사용하도록 한다.\n",
    "# 근데 RNN에서 나온 출력값은 [hp_batch_size, hp_n_step, hp_n_hidden]의 형태이다.\n",
    "\n",
    "# 그러므로 아래같은 형태로 행렬을 바꾸고자 한다.\n",
    "# [hp_batch_size, hp_n_step, hp_n_hidden] -> [hp_n_step, hp_batch_size, hp_n_hidden]\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "print(outputs)\n",
    "\n",
    "# 그리고 맨앞의 hp_n_step 차원을 제거하고, 마지막 단계의 결과값만 가져오도록 한다.\n",
    "# [hp_n_step, hp_batch_size, hp_n_hidden] -> [hp_batch_size, hp_n_hidden]\n",
    "outputs = outputs[-1]\n",
    "print(outputs)\n",
    "\n",
    "# 이제 인공신경망의 기본 수식인 y = X * W + b  (dense)를 이용하여 최종 결과를 만들자\n",
    "model = tf.matmul(outputs, W) + b\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수를 작성한다.\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=model,\n",
    "        labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(hp_leaning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.501\n",
      "Epoch: 0002 Avg. cost = 0.232\n",
      "Epoch: 0003 Avg. cost = 0.178\n",
      "Epoch: 0004 Avg. cost = 0.148\n",
      "Epoch: 0005 Avg. cost = 0.135\n",
      "Epoch: 0006 Avg. cost = 0.123\n",
      "Epoch: 0007 Avg. cost = 0.118\n",
      "Epoch: 0008 Avg. cost = 0.114\n",
      "Epoch: 0009 Avg. cost = 0.107\n",
      "Epoch: 0010 Avg. cost = 0.101\n",
      "Epoch: 0011 Avg. cost = 0.096\n",
      "Epoch: 0012 Avg. cost = 0.093\n",
      "Epoch: 0013 Avg. cost = 0.085\n",
      "Epoch: 0014 Avg. cost = 0.082\n",
      "Epoch: 0015 Avg. cost = 0.080\n",
      "Epoch: 0016 Avg. cost = 0.080\n",
      "Epoch: 0017 Avg. cost = 0.074\n",
      "Epoch: 0018 Avg. cost = 0.078\n",
      "Epoch: 0019 Avg. cost = 0.073\n",
      "Epoch: 0020 Avg. cost = 0.075\n",
      "Epoch: 0021 Avg. cost = 0.077\n",
      "Epoch: 0022 Avg. cost = 0.065\n",
      "Epoch: 0023 Avg. cost = 0.067\n",
      "Epoch: 0024 Avg. cost = 0.055\n",
      "Epoch: 0025 Avg. cost = 0.065\n",
      "Epoch: 0026 Avg. cost = 0.061\n",
      "Epoch: 0027 Avg. cost = 0.067\n",
      "Epoch: 0028 Avg. cost = 0.060\n",
      "Epoch: 0029 Avg. cost = 0.059\n",
      "Epoch: 0030 Avg. cost = 0.063\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 세션을 만들고 학습을 수행한다.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples / hp_batch_size)\n",
    "\n",
    "for epoch in range(hp_total_epoch):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(hp_batch_size)\n",
    "        batch_xs = batch_xs.reshape(hp_batch_size, hp_n_step, hp_n_input)\n",
    "        \n",
    "        _, cost_val = sess.run(\n",
    "            [optimizer, cost],\n",
    "            feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9674\n"
     ]
    }
   ],
   "source": [
    "# 학습결과를 확인해보자.\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, hp_n_step, hp_n_input)\n",
    "test_ys = mnist.test.labels\n",
    "\n",
    "print('정확도:', sess.run(accuracy, feed_dict={X: test_xs, Y: test_ys}))\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
